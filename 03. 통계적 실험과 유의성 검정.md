# 통계적 실험과 유의성 검정

## 통계적 실험과 유의성 검정

- 전형적인 통계 추론 과정
    1. 가설 수립
    2. 실험 설계
    3. 데이터 수집
    4. 추론 및 결론 도출

### A/B 테스트

- 대조군이 왜 필요한지?: 다른 환경은 동일하다 라는 보장을 할 수 없음 (통제 불가)
- 검정통계량을 미리 정해놔야함.
    - 실험 수행 후 검정통계량을 선택하면, 연구자 편향 발생

> 가설검정 (유의성 검정)

- 관찰된 효과가 우연에 의한 것인지 여부를 알아내는 것
- 귀무가설: 우연 때문이라는 가설 (=영가설)
- 대립가설: 귀무가설과 대조 (증명하고자 하는 가설)
- 일원검정: 한 방향으로만 우연히 일어날 확률을 계산하는 가설검정
- 이원검정: 양방향으로 우연히 일어날 확률을 계산하는 가설검정
- 통계적 가설검정은 우연히 일어난 일에 속지 않도록 보호하기 위한 방법으로 개발
- 일원검정
    - 극단적인 결과에 대해 한 방향으로만 고려하여 p값 계산
    - ex. B는 A보다 낫다
- 이원검정
    - 양방향으로 고려하여 p값 계산 (좀 더 보수적)
    - A는 B와 다르며 더 크거나 작을 수 있음
    - p값의 정확성이 그리 중요하지 않은 데이터과학에선 사실 크게 중요하지 않다.

> 재표본추출(리샘플링)

- 목표: 랜덤한 변동성을 알아보기 위함
- 관찰된 데이터의 값에서 표본을 반복적으로 추출
- 부트스트랩과 순열검정이라는 두 가지 유형이 있음.
    - 부트스트랩: 추정의 신뢰성을 평가하는데 사용
    - 순열검정: 두 개 이상의 그룹과 관련된 가설을 검증하는 데 사용

### 순열검정

- 두 개 이상의 그룹에 적용된 처리의 결과가 서로 다르지 않다는 것을 살피기 위한 것
1. 여러 그룹의 결과를 단일 데이터 집합으로 결합
2. 결합한 데이터를 섞은 후, 각 그룹들에 무작위 비복원추출
3. 지금 추출한 재표본에 대해 통계량을 다시 계산
4. 이렇게가 한 번의 순열 반복이며, *R*번 반복하여 검정 통계량의 순열분포를 얻음
- 실험을 통해 관찰된 차이가 순열로 보이는 차이 집합 안에 들어있다면, 우연의 범위 내에 존재하는 것
- 관찰된 차이가 대부분 순열 분포 바깥에 있다면, 우연이 아니며 통계적으로 유의하다.

### 순열의 종류

- 전체순열검정
    - 데이터를 무작위로 섞고 나누는 대신, 실제로 나눌 수 있는 모든 가능한 조합을 찾는다.
    - 샘플 크기가 작을 때 실용적
    - 정확한 결론을 보장하기에, 정확검정이라고도 함
- 부트스트랩 순열검정
    - 순열검정을 복원추출로 수행함
    - 리샘플링 과정에서 임의성 보장
- 리샘플링은 데이터가 정규분포를 따라야 한다는 가정도 필요 없고, 여러 제약에서 벗어나있다.

> 통계적 유의성과 p값

- 통계적 유의성: 실험의 결과가 우연히 일어난 것인지 아니면 우연히 일어날 수 없는 극단적인 것인지 판단하는 방법
- 실험 결과가 우연히 벌어질 수 있는 변동성의 바깥에 존재한다면, **유의하다**라고 표현한다.
- **p값?**
    - 귀무가설을 구체화한 기회 모델이 주어졌을 때, 관측된 결과와 같이 특이하거나 극단적인 결과를 얻을 확률
- 알파, 유의수준?
    - 실제 결과가 유의하다고 간주되기 위해, 우연에 의한 기회 결과가 능가해야하는 '비정상적인'가능성의 임계 확률
- 제 1종 오류
    - 우연에 의한 효과가 실제 효과라고 잘못 결론내림
    - 가설을 세울 때 1종 오류를 최소화하도록 설계해야함
- 제 2종 오류
    - 실제 효과가 있는데 우연이라고 잘못 결론내림
    - 표본 크기가 작아서 효과를 알 수 없다고 판단하는 것과 같음

> 유의수준(알파)과 p값

- 알파: 우연히 얻은 결과의 몇%보다 더 극단적인 결과이다! 할 때 그 몇%
    - 다시말해, 귀무가설 모델에서 '비정상'이라고 판단할 임계값
- p값: **랜덤모델이 주어졌을 때**, 그 결과가 관찰된 결과보다 더 극단적인 확률
    - 연구 가설이 사실일 확률을 측정하는것이 아니다.
    - p값 그 자체는 모델이나 가설에 대한 증거를 측정하기 위한 좋은 지표가 아니다!
- 데이터 과학에서 p값을 어떻게 바라보나?
    - 관심 있고 유용한 모델의 결과가 일반적인 랜덤 변이의 범위 내에 있는지 알고싶을 때 유용하게 쓸 수 있는 지표

### t검정

- 컴퓨터가 널리 보급되기 전, 재표본(리샘플링) 검정은 실용적이지 않았음.
    - 대신 표준적인 분포를 참고하였는데 그것이 t분포
- 스튜던트t 분포의 이름에서 비롯
- 원래는 단일 표본평균의 분포를 근사화하기 위해 개발한 것
- 검정통계량: 가설 검정에 사용되는 랜덤 변수
- t검정의 검정통계량은 t통계량
- 두 그룹의 평균을 비교하기 위해 사용할 수 있음

### 다중검정

- 추가하는 변수가 많을수록, 더 많은 모델을 사용할수록 우연에 의해 '유의미한'것으로 나타날 확률이 커짐
- 지도학습에선 이런 위험을 낮추기 위해 홀드아웃 세트를 사용
- 본페로니 수정: 통계학에선 검정 횟수에 따라 유의수준을 나눔 - 각 검정에 대해 더 작은 알파 적용
- 데이터 과학에선!
    - 데이터를 더 여러 번 사용하고 조작할수록 우연이 더 큰 역할을 할 수 있다는 것을 인식하자
    - 재표본추출과 시뮬레이션 결과들을 사용하여 무작위 모델의 기준값을 만들어 관찰된 결과를 비교

### 자유도*(d.f. - degrees of freedom)*

- 변화가 가능한 값들의 개수
- 표본 10개에 대한 평균을 알고있는 상태에서 9개의 표본값을 알면 나머지 표본 1개의 값은 자연스럽게 알게됨
- 데이터과학에선?
    - 유의성 검정 측면에선 중요하지 않음
    - 데이터가 크기때문에, n이든 n-1이든 결과에 크게 영향끼치지 않는다
    - 다만! 회귀에서 요인변수를 사용할 때는 관련있음
        - 회귀를 할 때 범주형 변수들을 n-1 지표 혹은 더미 변수로 요인화하는 것의 이유가 됨
        - 다중공선성을 피하기 위함임.
    - ex. 요일: 월~토요일이 아닌 요일은 일요일.
        - 월~토 지표 + 일요일 지표까지 추가하면 다중공선성 오차로 인해 회귀 실패

> 분산분석

- A/B 검정이 아닌, 여러 그룹 데이터를 비교
- 여러 그룹 간 유의미한 차이를 검정하는 것을 분산분석, ANOVA라고 함
    - 그룹 간 전체적인 편차가 발생할 수 있는 범위 내에 있는지 평가하기 위해
- ANOVA의 결과 중 유용한 점 중 하나는 그룹 처리, 상호작용 효과, 오차와 관련된 분산의 구성 요소들을 구분하는 데 있음
1. 모든 데이터를 한 상자에 모은다.
2. 5개의 값을 갖는 4개의 재표본을 섞어 추출
3. 각 그룹의 평균을 기록
4. 네 그룹 **평균 사이의 분산을 기록**
5. 2~4단계를 여러 번 반복 (ex. 1,000번)
- 재표집된 분산이 관찰된 변화를 초과한 정도는 어느정도일까? → p값

### F 통계량

- 잔차 오차로 인한 분산과 그룹 평균(처리 효과)의 분산에 대한 비율을 기초로 함
    - 비율이 높을수록 유의미하다고 할 수 있음
    - MS(처리)/MS(오차)
    - 잘 이해 안됨..;; p.133

### 이원분산분석

- 일원 ANOVA는 그룹(요소)가 하나임 ex. 페이지뷰 A,B,C,D 비교
- 이원분산분석은 그룹이 두개. ex. 그룹 A 평일, 그룹 A 주말, 그룹 B 평일, 그룹 B 주말
- 상호작용효과를 확인하는 식

> 카이제곱검정

- 단순 A/B검정을 넘어 동시에 여러가지를 한 번에 테스트
- 횟수 관련 데이터에 주로 사용, 예상되는 분포에 얼마나 잘 맞는지
- **카이제곱통계량**은 일반적으로 변수 간 독립성에 대한 귀무가설이 타당한지를 평가하기 위해
*r(row)* x *c(colomn)* 분할표를 사용한다.

### 카이제곱검정: 재표본추출 방법

- A안, B안, C안에 대한 배너에 대한 클릭수가 상이할 때, 높게 나온 수치가 유의한 수치인지 확인 필요
    - 재표본추출을 통해 결과값이 우연히 높게 나온 것인지 검정
    - 이 검정을 하려면 '기대'분포가 필요함
    - 각 배너 모두가 동일한 클릭율을 갖는다는 가정이 귀무가설
- 피어슨잔차(*R*) = (관측값 - 기댓값) / 기댓값의 제곱근
- 카이제곱통계량(*x*²)은 이 피어슨 잔차들의 제곱합
1. A, B, C안에서 나온 결과들을 모두 종합
2. 1의 그룹을 잘 섞은 다음 각각 동일한 표본수로 이루어지도록 다시 배분, 각각의 클릭수를 계산
3. 이렇게 얻은 횟수와 기대한 횟수의 차이를 제곱해서 합산
4. 2~3단계를 반복
5. 재표본추출을 통해 얻은 편차의 제곱합이 얼마나 자주 관측값을 초과하는지 → p값

### 카이제곱검정: 통계적 이론

- 적적한 표준 카이제곱분포는 자유도에 의해 결정
    - 분할표에서 자유도는 (*r*-1) * (*c*-1)
- 카이제곱분포는 일반적으로 한쪽으로 기울어져있고, 오른쪽으로 긴 꼬리를 갖는다.
- 카이제곱분포의 바깥쪽에 위치할수록 p값은 낮아진다

### 피셔의 정확검정

- 발생할 수 있는 모든 조합(순열)을 실제로 열거하고, 빈도를 집계하고, **관찰된 결과가 얼마나 극단적으로 발생할 수 있는지를 정확하게 결정**하는 절차
- 사건 발생 횟수가 매우 낮을 때, 특히 1자리 숫자이거나, 5개 이하인 경우.
- 일부 값이 매우 낮고, 다른 값이 상대적으로 매우 높은 경우(예를 들면 전환율 계산에서 분모)는 모든 가능한 순열을 계산하기는 어렵기 때문에, 완전한 정확검정 대신, 순열검정을 수행해야 할 수 있음.

### 카이제곱겁정, 피셔의 정확검정: 데이터 과학과의 관련성

- 직접적인 연간을  찾기는 어려움
- A/B나 A/B/C나 상관 없이, 대부분 실험에서 목표는 단순히 통계적 유의성을 찾는 것이 아니라, 최적의 처리 방법을 찾는 것이기 때문이다.
- 이를 위해 **멀티암드 밴딧 방법**이 더 정확한 해결책!
- 하지만.. ex. 웹 실험에서 적합한 표본 크기를 판별하는 일과 같은 예시에선 쓰일 수 있음
    - 예시의 실험은 클릭률이 매우 낮기 때문에, 수많은 실험에도 불구하고 집계 비율이 낮아, 결론내기가 어려움.
    - 이런 경우, 피셔의 정확검정, 카이제곱검정 등을 통해 검정력이나 표본 크기를 계산하는 데 유용하게 쓰일 수 있음.
- 데이터과학에선 필터로서 더 많이 사용
    - 어떤 효과나 특징에 대해 기본적인 유의성 검정을 넘어, 더 심층적인 분석이 필요할 지 여부를 결정
- 머신러닝에선
    - 자동으로 특징을 선택하기 위해 사용. 특징에 따라 클래스의 분포가 어떠한지 조사하고, 특정 클래스의 분포가 랜덤 변이에 비해 비정상적으로 크거나 작은 특징을 알아내는 등에 사용
        - (모르니까 일단 받아쓰기...)

### 멀티암드 밴딧 알고리즘

- 멀티암드 밴딧(MAB, multi-armed bandit) 알고리즘?
    - 멀티암드 밴딧
        - 고객이 선택할 수 있는 손잡이가 여러 개인 가상의 슬롯머신(손잡이=하나의 테스트)
        - 각 손잡이는 각기 다른 수익을 가져다줌, **다중 처리 실험에 대한 비유**
    - 전통적인 통계 방식보다 명시적인 최적화와 좀 더 빠른 의사결정을 가능하게 함
    - 여러 테스트, 특히 웹 테스트를 위해 이를 사용
- 여러가지 테스트 변수들을 동일하게 노출시키다가, 우위를 보이는 변수가 생기면 노출 빈도 높임
    - 그러나 다른 변수가 더 높아지면, 노출 빈도 변경
    - 그럼 노출하는 비율을 수정하는 알고리즘을 위한 파라미터는 무엇이 되어야 할까?
    노출시키는 비율을 언제 어떻게 수정해야할까?
- 엡실론-그리디 알고리즘
1. 0부터 1사이의 난수 생성
2. 이 숫자가 0과 엡실론(0과 1 사이의 값, 일반적으로 아주 작음) 사이에 존재하면 50/50의 확률로 동전 뒤집기를 시행한다.
3. 그 결과 동전이 앞면이면 제안 A를 표시한다.
4. 동전이 뒷면이면 제안 B를 표시한다.
5. 숫자가 엡실론보다 크면, 지금까지 가장 좋은 결과를 보인 제안을 표시한다.
    - 엡실론이 1이면, 우리는 A/B테스트를 하는 것
    - 엡실론이 0이면, 탐욕 알고리즘(greedy algorithm), 실험 없이 지금까지 알려진 가장 좋은 제안에 할당
- 톰슨의 샘플링
    - 엡실론-그리디 알고리즘보다 약간 더 복잡
    - 각 단계마다 표본을 추출(손잡이를 당김)하여 최고의 손잡이를 선택할 확률을 최대화
    - 어느 것이 가장 좋은 손잡이인지 모르지만, 연속적인 추출을 통해 얻는 수익을 관찰하여 더 많은 정보를 얻는다.
    - 톰슨 샘플링은 베이지언 방식을 사용한다. (베타 분포를 사용하여 수익의 일부 사전 분포를 가정)

### 전통적 A/B 검정과 MAB의 차이?

- 전통적 A/B
    - 검정 과정이 나오기까지 오래걸림
    - 그래서 수익이 낮은 것을 많이 시도할 수 있음
- MAB
    - 실험 도중에 얻은 정보를 사용하기때문에, 수익이 낮은 것에는 기회를 적게 줌
        - 이익 분배 효율화
    - 두 가지 이상의 처리를 효과적으로 다룰 수 있음
    - 수익이 높을 거싱라고 추정되는 쪽으로 이동시키기 위한 다양한 알고리즘이 존재함
        - 엡실론-그리디 알고리즘, 톰슨의 샘플링 등

> 검정력과 표본 크기

### 검정력

- 웹 테스트를 수행할 경우 실행 시간(처리 당 얼마나 많은 노출이 필요할 지)은 어떻게 결정할 지에 관한 내용
- 표본 크기에 대한 고려
    - 가설 검정이 실제로 처리 A와 B의 차이를 밝혀낼 수 있을까?
    - p값은 A와 B 사이에 실제 차이가 있는지에 따라 달라진다.
- 검정력
    - 특정 표본 조건(크기와 변이)에서 특정한 **효과크기**를 **알아낼 수** 있는 확률
        - 효과크기: 클릭률의 20%향상 과 같이 통계 검정을 통해 판단할 수 있는 효과의 **최소 크기 -** 이 정도면 효과가 있다! 에서 이 정도
        - 알아낸다: 차이가 없을 것이라는 영가설을 기각하고 실제 효과가 있다고 결론
    - 검정력 계산의 주된 용도는 결국 표본 크기가 어느정도 필요한지 추정하는 것

### 표본크기

- 효과 크기가 표본 크기를 좌우함
    - 효과 크기가 크다면 상대적으로 적은 수의 표본으로도 목표를 이룰 수 있음
    - 효과 크기가 작다면, 훨씬 큰 표본 필요
    - ex. ctr 50% 상승 이 필요한 경우 vs ctr 1% 상승이 필요한 경우
- 검정력, 표본크기 계산과 관련한 중요 4가지 요소들
    - 표본크기
    - 효과크기
    - 유의수준
    - 검정력
    - 이 중 3가지를 정하면 나머지 하나를 알 수 있음.

이 장에서 가장 중요한 개념은

1. 랜덤 변이에 관한 내용
2. 부트스트랩 및 순열검정
