# 데이터와 표본분포

## 데이터와 표본분포

- 빅데이터 시대 > 데이터의 질과 적합성은 좋지 않은데, 양은 늘어남
    - 표본 추출의 중요성 상대적으로 커짐
- 데이터 과학에서 모집단을 밝혀내는 것보다는, 표본 추출의 과정에 좀 더 신경씀

> 표집방법(표본을 얻는 방법)(샘플링)

- 임의표집(=랜덤표본추출, random sampling): 무작위로 표본 추출
- 층화표집(=층화표본추출, stratified sampling): 모집단을 층으로 나누고 그 층 내에서 무작위로 표본 추출
- 단순임의표본(=단순랜덤표본, simple random sampling): 층화 없이 랜덤표본추출로 얻은 표본
- 표본편향(=sample bias): 모집단을 잘못 대표한 표본
    - 표본편향이 발생치 않도록 비임의 방식을 지양해야함
- 복원추출, 비복원추출: 추출 후 다시 샘플을 모집단에 포함시키는가 안시키는가

> 편향

- 통계적 편향: 표본추출 과정에서 발생하는 계통적인 오차
- 데이터 품질이 데이터 양보다 더 중요한 경우가 있음
- 표본평균과 모평균
    - 표본에 대한 정보는 관찰로 얻고, 모집단에 대한 정보는 추론에 의해
- 선택편향
    - 의식, 무의식적으로 데이터를 선택적으로 고르는 관행
    - 방대한 검색 효과: 중복 데이터 모델링이나 너무 많은 예측변수를 고려하는 모델링에서 비롯되는 편향
    - 비랜덤표본추출
        - 자기선택 표본편향: 리뷰, 후기와 같이 작성자가 내용에 대한 주도권을 쥐고있는 것과 같은 상황. 리뷰를 남기는 행위 자체가 벌써 일반적이지 않다. 그 안에서 랜덤추출을 한다고 해도 결국 편향되어있음
    - 데이터 체리피킹(선별) 등
- 데이터 스누핑: 흥미로운 것을 찾아 광범위하게 데이터를 살피는 것
- 평균으로의 회귀
    - 예외적인 경우가 관찰되면, 그 다음에는 중간 정도의 경우가 관찰되는 경향
    - 예외 경우를 너무 특별히 의미부여하면 편향이 있을 수 있음

> 표본분포

- 모집단에서 얻은 샘플에 대한 표본통계량의 분포
- 통계량: 표본의 특징을 수치화한 값 ex. 평균, 분산
- 표본분포: 표본들로부터 얻은 **표본통계량**의 도수분포
- 중심극한정리(CLT): 표본크기가 커질수록 표본분포가 정규분포를 따르는 경향
- 표준오차: 표본들로 얻은 **표본통계량**의 변량 (표준편차가 아니다!)
- 표준편차: **개별 데이터 값들**의 변량
- 표본의 변동성
    - 다른 표본을 뽑았을 때 결과가 달라질까?
- **중심극한정리**
    - 모집단이 정규분포가 아니더라도, 표본 크기가 충분하고 데이터가 정규성을 크게 이탈하지 않으면, 여러 표본에서 추출한 평균은 정규분포를 따른다.
    - CLT덕분에 t분포같은 정규근사공식을 사용할 수 있다고 한다..
- 표준오차
    - 표본분포의 변동성
    - 표본 값들의 표준편차 s과 표본크기 n을 기반으로 한 통계량을 이용하여 추정 가능
    - 표준오차 = *SE* = *s / (n의 제곱근)*
    - 표준오차와 표본 크기의 사이를 n제곱근의 법칙 이라고도 한다.
        - 표준오차를 2배 줄이려면 표본크기를 4배 증가시켜야한다
        - 표본의 크기가 충분히 크면 그 평균의 분포가 점점 종모양이 되는것처럼
    - 표본오차를 추정하기 위해 새 샘플을 수집하기엔 너무 비효율적
    - 이를 개선하기 위해 부트스트랩이 탄생
- **부트스트랩**
    - 현재 표본에서 추가적으로 복원추출하고, 각 표본에 대한 통계량과 모델을 다시 계산
    - 데이터나 표본통계량이 정규분포를 따라야한다는 가정이 필요하지 않다
    1. 샘플 값을 뽑아서 기록하고 제자리에 놓는다
    2. *n*번 반복한다
    3. 재표본추출된 값의 평균을 기록한다
    4. 1~3단계를 *R*번 반복한다. (*R*- 부트스트랩 반복 횟수: 임의 설정)
    5. *R*개의 결과를 사용하여
        1. 그것들의 표준편차(표본평균의 표준오차)를 계산한다
        2. 히스토그램 또는 상자그림을 그린다
        3. 신뢰구간을 찾는다
    - R값이 클수록 표준오차나 신뢰구간에 대한 추정이 정확해짐
    - 신뢰구간을 구성하는 효과적인 방법!

> 신뢰구간

- 신뢰수준: 같은 모집단으로 같은 방식으로 얻은, 관심 통계량을 포함할 것으로 예상되는 신뢰구간의 백분율
- 구간끝점: 신뢰구간의 최상위, 최하위 끝점
1. 데이터에서 복원추출 방식으로 크기 n인 표본을 뽑는다(재표본추출)
2. 재표본추출한 표본에 대해 원하는 통계량을 기록한다.
3. 1~2단계를 R번 반복한다.
4. x% 신뢰구간을 구하기 위해, R개의 재표본 결과로부터 분포의 양쪽 끝에서
((100-x)/2)%만큼 잘라낸다
5. 절단한 점들은 x% 부트스트랩 신뢰구간의 양 끝점이다.
- 신뢰수준이 높을수록 구간이 더 넓어진다.
- 표본이 작을수록 구간이 넓어진다(불확실성이 더 커진다)

> 여러 분포들을 살펴보기

### 정규분포(=가우스 분포)

- 흔히 알고있는 종모양
- QQplot: 표본분포가 정규분포에 얼마나 가까운지 보여주는 그림
- z점수(=z score): 개별 데이터 포인트를 정규화한 결과
- '정규'란 '정상'적인 이 아님, 대부분의 표본분포 통계량이 정규분포를 따른다는 점에서 정규분포의 유용함이 드러나는 것.
- 하지만 부트스트랩 분포 혹은 경험적 확률분포를 구할 수 없을 경우 나타나는 끝판왕같은 놈
    - 경험적 확률분포(사전확률): 관측자가 관측을 하기 전 갖고있는 확률분포
    - ex) 주사위에서 4가 나올 확률 1/6

### 표준정규분포(z분포)

- x축의 단위가 평균의 표준편차로 표현됨
- (데이터 - 평균) / 표준편차 로 구할 수 있음
    - 이 과정을 표준화, 정규화 라고 부름
- 변환된 값은 z 점수라고 하며, 정규 분포를 z분포라고 한다.
- qqplot을 통해 정규분포와 가까운지 알 수 있다.
    - 대각선에 가까울수록 정규분포에 유사
- 긴 꼬리 분포
    - 꼬리(tail): 적은 수의 극단값이 주로 존재하는, 도수분포의 길고 좁은 부분
    - 왜도(skewness): 분포의 한쪽 꼬리가 반대쪽 다른 꼬리보다 긴 정도

### 스튜던트 t분포

- 정규분포와 비슷한데 꼬리만 조금 더 두꺼운 형태
- 적은 표본으로 모집단 평균을 추정하고자 정규분포 대신 사용

### 이항분포

- 시행: 독립된 결과를 가져오는 하나의 사건(베르누이 시행) ex. 동전던지기
- T/F, 0/1 등과 같이 두개의 결과만 갖으며, 두 사건이 일어날 확률이 5:5일 필요는 없다.
- 보통 덜 나오는 결과에 1을 지정하는 것이 일반적 (통상적으로 성공을 의미)
- 시행 횟수가 충분할 경우, 성공 확률인 *p*가 0.50에 가까울 때, 이항분포는 정규분포와 구별이 어렵다.

### 푸아송분포(포아송분포)

- 람다(=lambda): 단위 시간이나 단위 면적당 사건이 발생하는 비율
- 시간, 공간 단위로 표본을 수집할 때, 그 사건의 분포를 알려줌
- 지수분포
    - 사건과 사건 간 시간분포
    - ex. 웹사이트 방문이 일어나는 시간 사이
    - 지수분포와 푸아송분포 모두 람다값이 일정하게 유지되는것이 어려움.
    (왜냐면 현실에서는 변수가 많기 때문. 시간대별로 잘라도, 주중과 주말이 다름)
- 베이불분포
    - 지수, 푸아송분포의 개선버전
    - 시간에 따라 변화하는 사건 발생률(ex. 증가하는 기계 고장률)을 모델링 할 수 있다.
    - *B*>1일 경우 발생률은 시간이 지남에 따라 증가, 반대는 반대

- 빅데이터 시대에서 정확한 추정이 요구된다.
    - 랜덤표본추출의 원칙을 지키는 것이 중요하며, 편향을 줄이는 방향으로 데이터를 셋팅해야한다.
