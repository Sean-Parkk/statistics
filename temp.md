# 통계 Wiki

> 기초통계를 보기 쉽게 정리한 문서만들기

## 탐색적 데이터 분석, EDA(Exploratory Data Analysis)

- 오늘날 대부분의 데이터는 비정형 데이터
    - 데이터 분석을 위해서는 RAW 데이터를 정형화해야함
    - 혹은 정형화된 형태로 수집

### 데이터 분류 및 구조

> 정형 데이터

- 먼저, 분류를 왜 나누나요?
    - R, Python 등에서는 데이터를 종류별로 구분하여 처리함
- 연속형: 범위 데이터 *ex) 풍속, 지속시간*
- 이산: 횟수와 같은 정수형 데이터 *ex) 사건 발생 빈도, 구매 횟수*
- 범주형: 가능한 범위 안 데이터만 취함 (List, 다항형 데이터) *ex) 서울 내 구자치, TV스크린 종류*
- 이진: Binary (0,1) *ex) T or F*
- 순서형: 각 데이터 간 분명한 순위가 있는 범주형 데이터 *ex) 평점*
- 테이블 데이터
    - 데이터 프레임: 테이블 형태의 **데이터 구조**
    - 피처: 일반적으로 테이블의 각 열 (= 특징, 속성, 입력, 예측변수, 변수)
    - 결과(outcome): 데이터 과학 프로젝트 예측의 결과물 (=종속변수, 응답, 목표, 출력)
    - 레코드: 테이블에서의 각 행 (= 기록값, 사건(case), 사례, 관측값, 패턴, 샘플)
- 테이블 형식이 아닌 데이터 구조
    - 시계열 데이터, 위치 데이터, 그래프 등 있음

---

> 위치 추정

- 대표값 구하기
    - 각 피쳐들을 살펴보는 기초적 방법, 대부분의 값이 어디에 위치하는지 중심 경향성을 나타내는 추정값
- 대표값 종류 및 용어
    - 평균
    - 가중평균: 가중치를 곱한 총합 / 가중치의 총합
    - 중앙값
    - 가중 중앙값
    - 절사평균(=절단평균): 정해진 개수의 극단값을 제외한 평균값
    - 로버스트하다(=저항성 있다): 극단값들에 민감하지 않다는 것을 의미
    - 특잇값(=극단값)
- 평균과 중앙값
    - 평균은 특잇값과 같은 데이터에 민감함
    - 중앙값은 평균에 비해 비교적 로버스트한 위치 추정 방법
    - 평균에서도 절사평균, 가중평균 등으로 특잇값의 영향을 줄이기 위해 활용됨.
    - 결국 어떤 방법이든, 특잇값에 의한 데이터들의 대략적인 위치 왜곡을 막기 위해 고안된 것들

> 변이 추정

- 값이 얼마나 퍼져있는지, 밀집해있는지 등의 산포도를 나타냄
- 변이값 종류
    - 편차: 관측값과 추정값과의 차이
    - 분산: 평균과 편차를 제곱한 값들의 합을 n-1로 나눈 것
    - 표준편차: 분산의 제곱근
    - 평균절대편차: 평균과의 편차의 절댓값의 평균
    - 중간값의 중위절대편차: 중간값과의 편차의 절댓값의 중간값 (..?)
    - 범위: 최댓값과 최솟값의 차이
    - 순서통계량(=순위): 최소에서 최대까지 정렬된 데이터 값에 따른 계량형
    - 사분위범위(IQR): 75번째 백분위수와 25번쨰 백분위수 사이의 차이
- 분산, 표준편차 구할 시  n이 아니라 왜  n-1
    - 불편성 혹은 불편추정량을 없애기 위해
        - n으로 나누면 모집단에 해당하는 값보다 작게 나옴: 편향된(bias)값이 나올 수 있음
        - 조금이라도 더 정확한 값을 찾기 위해, 값을 크게 만들기 위해 n-1로 사용
    - 자유도
        - 표본평균을 알 경우, n개의 데이터를 무작위로 뽑았을 때 n번째 표본은 정해져있음
        - 이러한 상황을 방지하여 n개의 데이터 모두 독립적인 정보로 유지하기 위해 n-1
- 백분위수와 상자그림(boxplot)
    - 백분위수: 최댓(100%), 중앙(50%), 최솟값(0%) 및 25%, 75%값 등
        - 분포를 알기 쉬움
    - 백분위수를 표현하기 위한 상자그림
    - 특잇값(이상값)을 제외한 백분위수 표현

        ![Wiki/Untitled.png](Wiki/Untitled.png)

- 도수분포표와 히스토그램
    - 도수분포표: 변수의 범위를 **동일한 크기**로 나눔
    - 히스토그램: 도수분포표를 시각화
        - 도수 구간에 따라 시각화 모형이 달라짐
        - 구간을 너무 크게 설정하면 분포의 특징 파악을 놓칠 수 있음
        - 구간을 너무 작게 설정하면 큰 그림, 경향성을 볼 수 없음
        - 구간 별 불연속성이 나타남 (뚝뚝 끊김!)
    - 모멘트
        - 1차 모멘트: 위치
        - 2차 모멘트: 변이
        - 3차 모멘트: 왜도
        - 4차 모멘트: 첨도 (데이터가 극단값을 갖는 경향성)
- 밀도 추정
    - 히스토그램의 선형버전 (sns.distplot(df, kde=True, rug=False)
    - 커널밀도추정
- 막대도표 vs 히스토그램
    - 막대도표는 여러 변수를 표현 - 그래서 막대 간 떨어져있지!
    - 히스토그램은 하나의 변수를 구간으로 나눠서 표현
- 파이그래프
    - 막대도표 대신 파이그래프를 사용할 수도 있지만 시각적으로 안좋아서 잘 안씀
    - 실제량의 크기나 변화의 상황을 나타내는데 적당하지 않다.
    - 변화량을 비교할 때에도 극단적인 변화가 아니면, 한 번에 알아차리기 어렵다.
    - 여러 변수들을 표현하기에 적합하지 않다

> 범주형 데이터

- 범주?
    - 전혀 다른 집단 ex. 사과, 배
    - 정도를 나타내는 요인 ex. 낮음, 중간, 높음
    - 구간별로 나뉜 수치 데이터 ex. 20~24세, 25~29세
- 수치형을 범주형으로 나눠서 자주 봄.(나이를 5세씩 잘라서 본다든지)
- 최빈값
    - 범주형 데이터에선 잘 사용되지만, 수치형 데이터에는 잘 사용되지 않음
- 기댓값
    - 주로 가중평균하여 구함
- 데이터 시각화 전, 확인해야 할 것들

    ![Wiki/Untitled%201.png](Wiki/Untitled%201.png)

> 상관관계

- 이변량분석(두개의 변수 관계)
- 상관계수(피어슨 상관계수)
    - 0~1범위
- 상관행렬(행x열이 변수들로 이뤄진 일반적인 상관관계 table)
- 산점도(scatterplot)
    - 상관관계를 알 수 있는 시각화
    - 데이터가 비교적 적을 때에는 활용 가능
    - 데이터가 너무 많으면 특성 파악이 힘들다

### 다변량분석

- 평균, 분산은 일변량분석 (하나의 변수에 대한 분석법)
- 상관관계는 두개의 변수에 대한 분석, 이변량분석
- 수치형변수-수치형변수
    - 등고선, 육각형, 히트맵 등 사용
- 범주형-범주형(pd.crosstab)
    - 분할표(피벗) 으로 사용
- 범주형-수치형
- 바이올린도표 (violinplot)
    - 상자그림을 보완한 형태: 데이터의 분포를 더 자세히 볼 수 있다.
    - 데이터의 특잇값들을 더 명확하게 보여줌

---

## 데이터와 표본분포

- 빅데이터 시대 > 데이터의 질과 적합성은 좋지 않은데, 양은 늘어남
    - 표본 추출의 중요성 상대적으로 커짐
- 데이터 과학에서 모집단을 밝혀내는 것보다는, 표본 추출의 과정에 좀 더 신경씀

> 표집방법(표본을 얻는 방법)(샘플링)

- 임의표집(=랜덤표본추출, random sampling): 무작위로 표본 추출
- 층화표집(=층화표본추출, stratified sampling): 모집단을 층으로 나누고 그 층 내에서 무작위로 표본 추출
- 단순임의표본(=단순랜덤표본, simple random sampling): 층화 없이 랜덤표본추출로 얻은 표본
- 표본편향(=sample bias): 모집단을 잘못 대표한 표본
    - 표본편향이 발생치 않도록 비임의 방식을 지양해야함
- 복원추출, 비복원추출: 추출 후 다시 샘플을 모집단에 포함시키는가 안시키는가

> 편향

- 통계적 편향: 표본추출 과정에서 발생하는 계통적인 오차
- 데이터 품질이 데이터 양보다 더 중요한 경우가 있음
- 표본평균과 모평균
    - 표본에 대한 정보는 관찰로 얻고, 모집단에 대한 정보는 추론에 의해
- 선택편향
    - 의식, 무의식적으로 데이터를 선택적으로 고르는 관행
    - 방대한 검색 효과: 중복 데이터 모델링이나 너무 많은 예측변수를 고려하는 모델링에서 비롯되는 편향
    - 비랜덤표본추출
        - 자기선택 표본편향: 리뷰, 후기와 같이 작성자가 내용에 대한 주도권을 쥐고있는 것과 같은 상황. 리뷰를 남기는 행위 자체가 벌써 일반적이지 않다. 그 안에서 랜덤추출을 한다고 해도 결국 편향되어있음
    - 데이터 체리피킹(선별) 등
- 데이터 스누핑: 흥미로운 것을 찾아 광범위하게 데이터를 살피는 것
- 평균으로의 회귀
    - 예외적인 경우가 관찰되면, 그 다음에는 중간 정도의 경우가 관찰되는 경향
    - 예외 경우를 너무 특별히 의미부여하면 편향이 있을 수 있음

> 표본분포

- 모집단에서 얻은 샘플에 대한 표본통계량의 분포
- 통계량: 표본의 특징을 수치화한 값 ex. 평균, 분산
- 표본분포: 표본들로부터 얻은 **표본통계량**의 도수분포
- 중심극한정리(CLT): 표본크기가 커질수록 표본분포가 정규분포를 따르는 경향
- 표준오차: 표본들로 얻은 **표본통계량**의 변량 (표준편차가 아니다!)
- 표준편차: **개별 데이터 값들**의 변량
- 표본의 변동성
    - 다른 표본을 뽑았을 때 결과가 달라질까?
- **중심극한정리**
    - 모집단이 정규분포가 아니더라도, 표본 크기가 충분하고 데이터가 정규성을 크게 이탈하지 않으면, 여러 표본에서 추출한 평균은 정규분포를 따른다.
    - CLT덕분에 t분포같은 정규근사공식을 사용할 수 있다고 한다..
- 표준오차
    - 표본분포의 변동성
    - 표본 값들의 표준편차 s과 표본크기 n을 기반으로 한 통계량을 이용하여 추정 가능
    - 표준오차 = *SE* = *s / (n의 제곱근)*
    - 표준오차와 표본 크기의 사이를 n제곱근의 법칙 이라고도 한다.
        - 표준오차를 2배 줄이려면 표본크기를 4배 증가시켜야한다
        - 표본의 크기가 충분히 크면 그 평균의 분포가 점점 종모양이 되는것처럼
    - 표본오차를 추정하기 위해 새 샘플을 수집하기엔 너무 비효율적
    - 이를 개선하기 위해 부트스트랩이 탄생
- **부트스트랩**
    - 현재 표본에서 추가적으로 복원추출하고, 각 표본에 대한 통계량과 모델을 다시 계산
    - 데이터나 표본통계량이 정규분포를 따라야한다는 가정이 필요하지 않다
    1. 샘플 값을 뽑아서 기록하고 제자리에 놓는다
    2. *n*번 반복한다
    3. 재표본추출된 값의 평균을 기록한다
    4. 1~3단계를 *R*번 반복한다. (*R*- 부트스트랩 반복 횟수: 임의 설정)
    5. *R*개의 결과를 사용하여 
        1. 그것들의 표준편차(표본평균의 표준오차)를 계산한다
        2. 히스토그램 또는 상자그림을 그린다
        3. 신뢰구간을 찾는다
    - R값이 클수록 표준오차나 신뢰구간에 대한 추정이 정확해짐
    - 신뢰구간을 구성하는 효과적인 방법!

> 신뢰구간

- 신뢰수준: 같은 모집단으로 같은 방식으로 얻은, 관심 통계량을 포함할 것으로 예상되는 신뢰구간의 백분율
- 구간끝점: 신뢰구간의 최상위, 최하위 끝점
1. 데이터에서 복원추출 방식으로 크기 n인 표본을 뽑는다(재표본추출)
2. 재표본추출한 표본에 대해 원하는 통계량을 기록한다.
3. 1~2단계를 R번 반복한다.
4. x% 신뢰구간을 구하기 위해, R개의 재표본 결과로부터 분포의 양쪽 끝에서 
((100-x)/2)%만큼 잘라낸다
5. 절단한 점들은 x% 부트스트랩 신뢰구간의 양 끝점이다.
- 신뢰수준이 높을수록 구간이 더 넓어진다.
- 표본이 작을수록 구간이 넓어진다(불확실성이 더 커진다)

> 여러 분포들을 살펴보기

### 정규분포(=가우스 분포)

- 흔히 알고있는 종모양
- QQplot: 표본분포가 정규분포에 얼마나 가까운지 보여주는 그림
- z점수(=z score): 개별 데이터 포인트를 정규화한 결과
- '정규'란 '정상'적인 이 아님, 대부분의 표본분포 통계량이 정규분포를 따른다는 점에서 정규분포의 유용함이 드러나는 것.
- 하지만 부트스트랩 분포 혹은 경험적 확률분포를 구할 수 없을 경우 나타나는 끝판왕같은 놈
    - 경험적 확률분포(사전확률): 관측자가 관측을 하기 전 갖고있는 확률분포
    - ex) 주사위에서 4가 나올 확률 1/6

### 표준정규분포(z분포)

- x축의 단위가 평균의 표준편차로 표현됨
- (데이터 - 평균) / 표준편차 로 구할 수 있음
    - 이 과정을 표준화, 정규화 라고 부름
- 변환된 값은 z 점수라고 하며, 정규 분포를 z분포라고 한다.
- qqplot을 통해 정규분포와 가까운지 알 수 있다.
    - 대각선에 가까울수록 정규분포에 유사
- 긴 꼬리 분포
    - 꼬리(tail): 적은 수의 극단값이 주로 존재하는, 도수분포의 길고 좁은 부분
    - 왜도(skewness): 분포의 한쪽 꼬리가 반대쪽 다른 꼬리보다 긴 정도

### 스튜던트 t분포

- 정규분포와 비슷한데 꼬리만 조금 더 두꺼운 형태
- 적은 표본으로 모집단 평균을 추정하고자 정규분포 대신 사용

### 이항분포

- 시행: 독립된 결과를 가져오는 하나의 사건 ex. 동전던지기
- T/F, 0/1 등과 같이 두개의 결과만 갖으며, 두 사건이 일어날 확률이 5:5일 필요는 없다.
- 보통 덜 나오는 결과에 1을 지정하는 것이 일반적 (통상적으로 성공을 의미)
- 시행 횟수가 충분할 경우, 성공 확률인 *p*가 0.50에 가까울 때, 이항분포는 정규분포와 구별이 어렵다.

### 푸아송분포(포아송분포)

- 람다(=lambda): 단위 시간이나 단위 면적당 사건이 발생하는 비율
- 시간, 공간 단위로 표본을 수집할 때, 그 사건의 분포를 알려줌
- 지수분포
    - 사건과 사건 간 시간분포
    - ex. 웹사이트 방문이 일어나는 시간 사이
    - 지수분포와 푸아송분포 모두 람다값이 일정하게 유지되는것이 어려움.
    (왜냐면 현실에서는 변수가 많기 때문. 시간대별로 잘라도, 주중과 주말이 다름)
- 베이불분포
    - 지수, 푸아송분포의 개선버전
    - 시간에 따라 변화하는 사건 발생률(ex. 증가하는 기계 고장률)을 모델링 할 수 있다.
    - *B*>1일 경우 발생률은 시간이 지남에 따라 증가, 반대는 반대
- 빅데이터 시대에서 정확한 추정이 요구된다.
    - 랜덤표본추출의 원칙을 지키는 것이 중요하며, 편향을 줄이는 방향으로 데이터를 셋팅해야한다.

---

## 통계적 실험과 유의성 검정

- 전형적인 통계 추론 과정
    1. 가설 수립
    2. 실험 설계
    3. 데이터 수집
    4. 추론 및 결론 도출

### A/B 테스트

- 대조군이 왜 필요한지?: 다른 환경은 동일하다 라는 보장을 할 수 없음 (통제 불가)
- 검정통계량을 미리 정해놔야함.
    - 실험 수행 후 검정통계량을 선택하면, 연구자 편향 발생

> 가설검정 (유의성 검정)

- 관찰된 효과가 우연에 의한 것인지 여부를 알아내는 것
- 귀무가설: 우연 때문이라는 가설 (=영가설)
- 대립가설: 귀무가설과 대조 (증명하고자 하는 가설)
- 일원검정: 한 방향으로만 우연히 일어날 확률을 계산하는 가설검정
- 이원검정: 양방향으로 우연히 일어날 확률을 계산하는 가설검정
- 통계적 가설검정은 우연히 일어난 일에 속지 않도록 보호하기 위한 방법으로 개발
- 일원검정
    - 극단적인 결과에 대해 한 방향으로만 고려하여 p값 계산
    - ex. B는 A보다 낫다
- 이원검정
    - 양방향으로 고려하여 p값 계산 (좀 더 보수적)
    - A는 B와 다르며 더 크거나 작을 수 있음
    - p값의 정확성이 그리 중요하지 않은 데이터과학에선 사실 크게 중요하지 않다.

> 재표본추출(리샘플링)

- 목표: 랜덤한 변동성을 알아보기 위함
- 관찰된 데이터의 값에서 표본을 반복적으로 추출
- 부트스트랩과 순열검정이라는 두 가지 유형이 있음.
    - 부트스트랩: 추정의 신뢰성을 평가하는데 사용
    - 순열검정: 두 개 이상의 그룹과 관련된 가설을 검증하는 데 사용

### 순열검정

- 두 개 이상의 그룹에 적용된 처리의 결과가 서로 다르지 않다는 것을 살피기 위한 것
1. 여러 그룹의 결과를 단일 데이터 집합으로 결합
2. 결합한 데이터를 섞은 후, 각 그룹들에 무작위 비복원추출
3. 지금 추출한 재표본에 대해 통계량을 다시 계산
4. 이렇게가 한 번의 순열 반복이며, *R*번 반복하여 검정 통계량의 순열분포를 얻음
- 실험을 통해 관찰된 차이가 순열로 보이는 차이 집합 안에 들어있다면, 우연의 범위 내에 존재하는 것
- 관찰된 차이가 대부분 순열 분포 바깥에 있다면, 우연이 아니며 통계적으로 유의하다.

### 순열의 종류

- 전체순열검정
    - 데이터를 무작위로 섞고 나누는 대신, 실제로 나눌 수 있는 모든 가능한 조합을 찾는다.
    - 샘플 크기가 작을 때 실용적
    - 정확한 결론을 보장하기에, 정확검정이라고도 함
- 부트스트랩 순열검정
    - 순열검정을 복원추출로 수행함
    - 리샘플링 과정에서 임의성 보장
- 리샘플링은 데이터가 정규분포를 따라야 한다는 가정도 필요 없고, 여러 제약에서 벗어나있다.

> 통계적 유의성과 p값

- 통계적 유의성: 실험의 결과가 우연히 일어난 것인지 아니면 우연히 일어날 수 없는 극단적인 것인지 판단하는 방법
- 실험 결과가 우연히 벌어질 수 있는 변동성의 바깥에 존재한다면, **유의하다**라고 표현한다.
- **p값?**
    - 귀무가설을 구체화한 기회 모델이 주어졌을 때, 관측된 결과와 같이 특이하거나 극단적인 결과를 얻을 확률
- 알파, 유의수준?
    - 실제 결과가 유의하다고 간주되기 위해, 우연에 의한 기회 결과가 능가해야하는 '비정상적인'가능성의 임계 확률
- 제 1종 오류
    - 우연에 의한 효과가 실제 효과라고 잘못 결론내림
    - 가설을 세울 때 1종 오류를 최소화하도록 설계해야함
- 제 2종 오류
    - 실제 효과가 있는데 우연이라고 잘못 결론내림
    - 표본 크기가 작아서 효과를 알 수 없다고 판단하는 것과 같음

> 유의수준(알파)과 p값

- 알파: 우연히 얻은 결과의 몇%보다 더 극단적인 결과이다! 할 때 그 몇%
    - 다시말해, 귀무가설 모델에서 '비정상'이라고 판단할 임계값
- p값: **랜덤모델이 주어졌을 때**, 그 결과가 관찰된 결과보다 더 극단적인 확률
    - 연구 가설이 사실일 확률을 측정하는것이 아니다.
    - p값 그 자체는 모델이나 가설에 대한 증거를 측정하기 위한 좋은 지표가 아니다!
- 데이터 과학에서 p값을 어떻게 바라보나?
    - 관심 있고 유용한 모델의 결과가 일반적인 랜덤 변이의 범위 내에 있는지 알고싶을 때 유용하게 쓸 수 있는 지표

### t검정

- 컴퓨터가 널리 보급되기 전, 재표본(리샘플링) 검정은 실용적이지 않았음.
    - 대신 표준적인 분포를 참고하였는데 그것이 t분포
- 스튜던트t 분포의 이름에서 비롯
- 원래는 단일 표본평균의 분포를 근사화하기 위해 개발한 것
- 검정통계량: 가설 검정에 사용되는 랜덤 변수
- t검정의 검정통계량은 t통계량
- 두 그룹의 평균을 비교하기 위해 사용할 수 있음

### 다중검정

- 추가하는 변수가 많을수록, 더 많은 모델을 사용할수록 우연에 의해 '유의미한'것으로 나타날 확률이 커짐
- 지도학습에선 이런 위험을 낮ㅊ추기 위해 홀드아웃 세트를 사용
- 본페로니 수정: 통계학에선 검정 횟수에 따라 유의수준을 나눔 - 각 검정에 대해 더 작은 알파 적용
- 데이터 과학에선!
    - 데이터를 더 여러 번 사용하고 조작할수록 우연이 더 큰 역할을 할 수 있다는 것을 인식하자
    - 재표본추출과 시뮬레이션 결과들을 사용하여 무작위 모델의 기준값을 만들어 관찰된 결과를 비교

### 자유도*(d.f. - degrees of freedom)*

- 변화가 가능한 값들의 개수
- 표본 10개에 대한 평균을 알고있는 상태에서 9개의 표본값을 알면 나머지 표본 1개의 값은 자연스럽게 알게됨
- 데이터과학에선?
    - 유의성 검정 측면에선 중요하지 않음
    - 데이터가 크기때문에, n이든 n-1이든 결과에 크게 영향끼치지 않는다
    - 다만! 회귀에서 요인변수를 사용할 때는 관련있음
        - 회귀를 할 때 범주형 변수들을 n-1 지표 혹은 더미 변수로 요인화하는 것의 이유가 됨
        - 다중공선성을 피하기 위함임.
    - ex. 요일: 월~토요일이 아닌 요일은 일요일.
        - 월~토 지표 + 일요일 지표까지 추가하면 다중공선성 오차로 인해 회귀 실패

### 분산분석

- A/B 검정이 아닌, 여러 그룹 데이터를 비교
- 여러 그룹 간 유의미한 차이를 검정하는 것을 분산분석, ANOVA라고 함
1. 모든 데이터를 한 상자에 모은다.
2. 5개의 값을 갖는 4개의 재표본을 섞어 추출
3. 각 그룹의 평균을 기록
4. 네 그룹 평균 사이의 분산을 기록
5. 2~4단계를 여러 번 반복 (ex. 1,000번)
- 재표집된 분산이 관찰된 변화를 초과한 시간은 어느정도일까? → p값

### F 통계량

- 잔차 오차로 인한 분산과 그룹 평균(처리 효과)의 분산에 대한 비율을 기초로 함
    - 비율이 높을수록 유의미하다고 할 수 있음
    -
